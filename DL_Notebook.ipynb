{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "amazing-madison",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import initializers\n",
    "from keras import metrics\n",
    "import matplotlib.pyplot as mpl\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "missing-dress",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kayde\\OneDrive\\Desktop\\mannada\\RainfallData\n"
     ]
    }
   ],
   "source": [
    "#Get the current working directory\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sapphire-billy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the variables as recorded by the station\n",
    "variables = [\n",
    "        'dswr',\n",
    "        'lftx',\n",
    "        'mslp',\n",
    "        'p__f',\n",
    "        'p__u',\n",
    "        'p__v',\n",
    "        'p__z',\n",
    "        'p_th',\n",
    "        'p_zh',\n",
    "        'p5_f',\n",
    "        'p5_u',\n",
    "        'p5_v',\n",
    "        'p5_z',\n",
    "        'p5th',\n",
    "        'p5zh',\n",
    "        'p8_f',\n",
    "        'p8_u',\n",
    "        'p8_v',\n",
    "        'p8_z',\n",
    "        'p8th',\n",
    "        'p8zh',\n",
    "        'p500',\n",
    "        'p850',\n",
    "        'pottmp',\n",
    "        'pr_wtr',\n",
    "        'prec',\n",
    "        'r500',\n",
    "        'r850',\n",
    "        'rhum',\n",
    "        'shum',\n",
    "        'temp',\n",
    "]\n",
    "\n",
    "#The three regions\n",
    "regions = [\n",
    "        '82.5', #A\n",
    "        '85.0', #B\n",
    "        '87.5', #C\n",
    "]\n",
    "\n",
    "'''\n",
    "TAKING IN ALL THE X VARIABLES\n",
    "'''\n",
    "\n",
    "#define an empty dictionary\n",
    "boxes = {}\n",
    "\n",
    "#iterating over regions\n",
    "for region in regions:\n",
    "    \n",
    "    df_li = pd.DataFrame() # empty dataframe\n",
    "    \n",
    "    #iterating over variables\n",
    "    for var in variables:\n",
    "        \n",
    "        path = os.path.join(cwd,\"DATA\\\\BOX_20N_%sE\\\\ncep_%s.dat\"%(region,var)) # Cleverly curated path for automation\n",
    "        \n",
    "        with open(path) as file: #open the respected variable file for the region\n",
    "            \n",
    "            temp = file.read().splitlines()\n",
    "            temp = [float(i) for i in temp]\n",
    "            \n",
    "        df_li[region + '_' + var] = temp #and for every variable, store that data under header: <coordinate_variable>\n",
    "        \n",
    "    boxes[region]=df_li #and assign that dataframe for every region\n",
    "    \n",
    "'''\n",
    "TAKING IN ALL THE Y VALUES\n",
    "'''\n",
    "\n",
    "rain = []\n",
    "\n",
    "for i in range(5): # iterate from 0 to 4 i.e. 5 times\n",
    "    \n",
    "    path = os.path.join(cwd,\"DATA\\\\rain%d.dat\"%(i+1)) # join cwd to path of rain data\n",
    "    \n",
    "    with open(path) as file:\n",
    "        \n",
    "        lines = file.read().splitlines()\n",
    "        lines = [float(i) for i in lines]\n",
    "        rain.append( lines )  #store in rain list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "searching-producer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#time for some data refining and model training\n",
    "\n",
    "#Trimming BOXES, this is to match with the rain data, day-by-day\n",
    "for region in regions:\n",
    "    boxes[region] = boxes[region].iloc[4749:,] # removing 4749 rows from front\n",
    "    boxes[region] = boxes[region].iloc[:10957,] # keeping only 10957 of the rest\n",
    "\n",
    "#sample take BOX A and PLACE 1\n",
    "df = boxes['82.5']\n",
    "rain1 = rain[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "indoor-quarterly",
   "metadata": {},
   "outputs": [],
   "source": [
    "class predictionModel:\n",
    "    '''\n",
    "    This is a class defining the Prediction Neural Network, Its input filtering,\n",
    "    '''\n",
    "    def __init__(self,X,Y,classStr,N=1,K=31):\n",
    "        if classStr == 'regressor':\n",
    "            self.__model = self.__neuralNetworkRegressor(N,K)\n",
    "        elif classStr == 'classifier':\n",
    "            self.__model = self.__neuralNetworkClassifier(N,K)\n",
    "        else:\n",
    "            print('\\nError: model %s not found'%(classStr))\n",
    "        self.__K = K\n",
    "        self.__N = N\n",
    "        self.__xdata = X\n",
    "        self.__ydata = Y\n",
    "        self.__class = classStr\n",
    "    def __neuralNetworkRegressor(self,N,K):\n",
    "        model = Sequential(\n",
    "            [\n",
    "                Dense(\n",
    "                    31*N,\n",
    "                    input_dim=31*N,\n",
    "                    activation='sigmoid', #next layer is relu, so it needs normalization\n",
    "                    kernel_initializer=initializers.GlorotNormal(seed=None), #glorot works good with sigmoid\n",
    "                    bias_initializer='zeros',\n",
    "                ),\n",
    "                Dense(\n",
    "                    K,\n",
    "                    activation='relu', #relu, for better regression\n",
    "                    kernel_initializer=initializers.HeNormal(seed=None), #He Normal goes good with relu\n",
    "                    bias_initializer='zeros',\n",
    "                ),\n",
    "                Dense(\n",
    "                    1,\n",
    "                    kernel_initializer='normal',\n",
    "                    bias_initializer='zeros',\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "        model.compile(loss='mean_squared_error',optimizer='adam',metrics=[metrics.MeanSquaredError()])\n",
    "        return model\n",
    "    \n",
    "    def __neuralNetworkClassifier(self,N,K):\n",
    "        \n",
    "        model = Sequential(\n",
    "            [\n",
    "                Dense(\n",
    "                    31*N,\n",
    "                    input_dim=31*N,\n",
    "                    activation='relu',\n",
    "                    kernel_initializer=initializers.HeNormal(seed=None), #He Normal goes good with relu\n",
    "                    bias_initializer='zeros',\n",
    "                ),\n",
    "                Dense(\n",
    "                    K,\n",
    "                    activation='relu', \n",
    "                    kernel_initializer=initializers.HeNormal(seed=None), #He Normal goes good with relu\n",
    "                    bias_initializer='zeros',\n",
    "                ),\n",
    "                Dense(\n",
    "                    1,\n",
    "                    activation='sigmoid',\n",
    "                    kernel_initializer='normal',\n",
    "                    bias_initializer='zeros',\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "        model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "        return model\n",
    "    \n",
    "    def trainNetwork(self):\n",
    "        xtrain, xtest, ytrain, ytest = train_test_split(self.__xdata,self.__ydata,test_size=0.2)#splitting test-train\n",
    "        print(\"Initiating Training Sequence\\n\")\n",
    "        history = self.__model.fit(\n",
    "            xtrain,\n",
    "            ytrain,\n",
    "            epochs = 10,\n",
    "            batch_size = 5,\n",
    "        )\n",
    "        print(\"\\n\\nInitiating Testing Sequence\\n\")\n",
    "        metrics = self.__model.evaluate(\n",
    "            xtest,\n",
    "            ytest,\n",
    "            batch_size = 5,\n",
    "        )\n",
    "    def evaluateNetwork(self):\n",
    "        '''\n",
    "        This Function isn't really working now,\n",
    "        Will come back later\n",
    "        '''\n",
    "        print(\"\\nInitiating Evaluation Sequence\\n\")\n",
    "        evaluators=[\n",
    "            ('standardize',StandardScaler()),\n",
    "            ('mlp',KerasRegressor(\n",
    "                build_fn =  self.__neuralNetwork(self.__N,self.__K),\n",
    "                epochs = 10,\n",
    "                batch_size = 5,\n",
    "                verbose = 0,\n",
    "            )),\n",
    "        ]\n",
    "        pipeline = Pipeline(evaluators)\n",
    "        results = cross_val_score(\n",
    "            pipeline,\n",
    "            self.__xdata,\n",
    "            self.__ydata,\n",
    "            cv = KFold(n_splits=10)\n",
    "        )\n",
    "        print(\"Standardized: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "romantic-twist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating Training Sequence\n",
      "\n",
      "Epoch 1/10\n",
      "1753/1753 [==============================] - 3s 2ms/step - loss: 63.7741 - mean_squared_error: 63.7741\n",
      "Epoch 2/10\n",
      "1753/1753 [==============================] - 3s 2ms/step - loss: 56.2010 - mean_squared_error: 56.2010\n",
      "Epoch 3/10\n",
      "1753/1753 [==============================] - 3s 1ms/step - loss: 55.2694 - mean_squared_error: 55.2694\n",
      "Epoch 4/10\n",
      "1753/1753 [==============================] - 2s 1ms/step - loss: 54.8901 - mean_squared_error: 54.8901\n",
      "Epoch 5/10\n",
      "1753/1753 [==============================] - 3s 1ms/step - loss: 55.0772 - mean_squared_error: 55.0772\n",
      "Epoch 6/10\n",
      "1753/1753 [==============================] - 2s 1ms/step - loss: 54.1573 - mean_squared_error: 54.1573\n",
      "Epoch 7/10\n",
      "1753/1753 [==============================] - 3s 2ms/step - loss: 54.1967 - mean_squared_error: 54.1967\n",
      "Epoch 8/10\n",
      "1753/1753 [==============================] - 3s 2ms/step - loss: 54.0544 - mean_squared_error: 54.0544\n",
      "Epoch 9/10\n",
      "1753/1753 [==============================] - 3s 2ms/step - loss: 54.0417 - mean_squared_error: 54.0417\n",
      "Epoch 10/10\n",
      "1753/1753 [==============================] - 3s 1ms/step - loss: 53.8673 - mean_squared_error: 53.8673\n",
      "\n",
      "\n",
      "Initiating Testing Sequence\n",
      "\n",
      "439/439 [==============================] - 1s 1ms/step - loss: 53.6992 - mean_squared_error: 53.6992\n"
     ]
    }
   ],
   "source": [
    "ydat = rain1.copy()\n",
    "xdat = df.values.tolist()\n",
    "rainFallPredictor = predictionModel(xdat,ydat,'regressor',1,10)\n",
    "rainFallPredictor.trainNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "authentic-asthma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating Training Sequence\n",
      "\n",
      "Epoch 1/10\n",
      "481/481 [==============================] - 1s 2ms/step - loss: 179.7392 - mean_squared_error: 179.7392\n",
      "Epoch 2/10\n",
      "481/481 [==============================] - 1s 2ms/step - loss: 174.3905 - mean_squared_error: 174.3905\n",
      "Epoch 3/10\n",
      "481/481 [==============================] - 1s 2ms/step - loss: 170.8650 - mean_squared_error: 170.8650\n",
      "Epoch 4/10\n",
      "481/481 [==============================] - 1s 2ms/step - loss: 168.4039 - mean_squared_error: 168.4039\n",
      "Epoch 5/10\n",
      "481/481 [==============================] - 1s 2ms/step - loss: 167.3397 - mean_squared_error: 167.3397\n",
      "Epoch 6/10\n",
      "481/481 [==============================] - 1s 2ms/step - loss: 165.4400 - mean_squared_error: 165.4400\n",
      "Epoch 7/10\n",
      "481/481 [==============================] - 1s 2ms/step - loss: 165.1823 - mean_squared_error: 165.1823\n",
      "Epoch 8/10\n",
      "481/481 [==============================] - 1s 2ms/step - loss: 163.0267 - mean_squared_error: 163.0267\n",
      "Epoch 9/10\n",
      "481/481 [==============================] - 1s 2ms/step - loss: 164.6673 - mean_squared_error: 164.6673\n",
      "Epoch 10/10\n",
      "481/481 [==============================] - 1s 2ms/step - loss: 163.1629 - mean_squared_error: 163.1629\n",
      "\n",
      "\n",
      "Initiating Testing Sequence\n",
      "\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 205.5634 - mean_squared_error: 205.5634\n"
     ]
    }
   ],
   "source": [
    "df_2 = df.copy()\n",
    "df_2['rain'] = rain1\n",
    "df_2.drop(df_2[df_2['rain'] == 0].index, inplace = True)\n",
    "ydata_2 = df_2['rain'].values.tolist()\n",
    "df_2 = df_2.drop(['rain'],axis=1)\n",
    "xdata_2=df_2.values.tolist()\n",
    "rainFallPredictor2 = predictionModel(xdata_2,ydata_2,'regressor',1,400)\n",
    "rainFallPredictor2.trainNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "another-testing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating Training Sequence\n",
      "\n",
      "Epoch 1/10\n",
      "1753/1753 [==============================] - 3s 2ms/step - loss: 0.7692 - accuracy: 0.7876\n",
      "Epoch 2/10\n",
      "1753/1753 [==============================] - 3s 2ms/step - loss: 0.4976 - accuracy: 0.8245\n",
      "Epoch 3/10\n",
      "1753/1753 [==============================] - 3s 2ms/step - loss: 0.4126 - accuracy: 0.8365\n",
      "Epoch 4/10\n",
      "1753/1753 [==============================] - 3s 2ms/step - loss: 0.3737 - accuracy: 0.8467\n",
      "Epoch 5/10\n",
      "1753/1753 [==============================] - 3s 2ms/step - loss: 0.3575 - accuracy: 0.8496\n",
      "Epoch 6/10\n",
      "1753/1753 [==============================] - 3s 2ms/step - loss: 0.3435 - accuracy: 0.8518\n",
      "Epoch 7/10\n",
      "1753/1753 [==============================] - 3s 2ms/step - loss: 0.3387 - accuracy: 0.8524\n",
      "Epoch 8/10\n",
      "1753/1753 [==============================] - ETA: 0s - loss: 0.3354 - accuracy: 0.85 - 3s 2ms/step - loss: 0.3358 - accuracy: 0.8545\n",
      "Epoch 9/10\n",
      "1753/1753 [==============================] - 3s 2ms/step - loss: 0.3303 - accuracy: 0.8578\n",
      "Epoch 10/10\n",
      "1753/1753 [==============================] - 3s 2ms/step - loss: 0.3293 - accuracy: 0.8569\n",
      "\n",
      "\n",
      "Initiating Testing Sequence\n",
      "\n",
      "439/439 [==============================] - 1s 1ms/step - loss: 0.3489 - accuracy: 0.8568\n"
     ]
    }
   ],
   "source": [
    "ydata_3 = rain1\n",
    "for i in range(len(ydata_3)):\n",
    "    if ydata_3[i] > 0:\n",
    "        ydata_3[i] = 1;\n",
    "xdata_3 = df.values.tolist()\n",
    "rainFallPredictor3 = predictionModel(xdata_3,ydata_3,'classifier',1,200)\n",
    "rainFallPredictor3.trainNetwork()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
