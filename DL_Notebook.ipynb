{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "amazing-madison",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import initializers\n",
    "import matplotlib.pyplot as mpl\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "missing-dress",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kayde\\OneDrive\\Desktop\\mannada\\RainfallData\n"
     ]
    }
   ],
   "source": [
    "#Get the current working directory\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "sapphire-billy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the variables as recorded by the station\n",
    "variables = [\n",
    "        'dswr',\n",
    "        'lftx',\n",
    "        'mslp',\n",
    "        'p__f',\n",
    "        'p__u',\n",
    "        'p__v',\n",
    "        'p__z',\n",
    "        'p_th',\n",
    "        'p_zh',\n",
    "        'p5_f',\n",
    "        'p5_u',\n",
    "        'p5_v',\n",
    "        'p5_z',\n",
    "        'p5th',\n",
    "        'p5zh',\n",
    "        'p8_f',\n",
    "        'p8_u',\n",
    "        'p8_v',\n",
    "        'p8_z',\n",
    "        'p8th',\n",
    "        'p8zh',\n",
    "        'p500',\n",
    "        'p850',\n",
    "        'pottmp',\n",
    "        'pr_wtr',\n",
    "        'prec',\n",
    "        'r500',\n",
    "        'r850',\n",
    "        'rhum',\n",
    "        'shum',\n",
    "        'temp',\n",
    "]\n",
    "\n",
    "#The three regions\n",
    "regions = [\n",
    "        '82.5', #A\n",
    "        '85.0', #B\n",
    "        '87.5', #C\n",
    "]\n",
    "\n",
    "'''\n",
    "TAKING IN ALL THE X VARIABLES\n",
    "'''\n",
    "\n",
    "#define an empty dictionary\n",
    "boxes = {}\n",
    "\n",
    "#iterating over regions\n",
    "for region in regions:\n",
    "    \n",
    "    df_li = pd.DataFrame() # empty dataframe\n",
    "    \n",
    "    #iterating over variables\n",
    "    for var in variables:\n",
    "        \n",
    "        path = os.path.join(cwd,\"DATA\\\\BOX_20N_%sE\\\\ncep_%s.dat\"%(region,var)) # Cleverly curated path for automation\n",
    "        \n",
    "        with open(path) as file: #open the respected variable file for the region\n",
    "            \n",
    "            temp = file.read().splitlines()\n",
    "            temp = [float(i) for i in temp]\n",
    "            \n",
    "        df_li[region + '_' + var] = temp #and for every variable, store that data under header: <coordinate_variable>\n",
    "        \n",
    "    boxes[region]=df_li #and assign that dataframe for every region\n",
    "    \n",
    "'''\n",
    "TAKING IN ALL THE Y VALUES\n",
    "'''\n",
    "\n",
    "rain = []\n",
    "\n",
    "for i in range(5): # iterate from 0 to 4 i.e. 5 times\n",
    "    \n",
    "    path = os.path.join(cwd,\"DATA\\\\rain%d.dat\"%(i+1)) # join cwd to path of rain data\n",
    "    \n",
    "    with open(path) as file:\n",
    "        \n",
    "        lines = file.read().splitlines()\n",
    "        lines = [float(i) for i in lines]\n",
    "        rain.append( lines )  #store in rain list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "searching-producer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#time for some data refining and model training\n",
    "\n",
    "#Trimming BOXES, this is to match with the rain data, day-by-day\n",
    "for region in regions:\n",
    "    boxes[region] = boxes[region].iloc[4749:,] # removing 4749 rows from front\n",
    "    boxes[region] = boxes[region].iloc[:10957,] # keeping only 10957 of the rest\n",
    "\n",
    "#sample take BOX A and PLACE 1\n",
    "df = boxes['82.5']\n",
    "rain1 = rain[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "indoor-quarterly",
   "metadata": {},
   "outputs": [],
   "source": [
    "class predictionModel:\n",
    "    '''\n",
    "    This is a class defining the Prediction Neural Network, Its input filtering,\n",
    "    '''\n",
    "    def __init__(self,X,Y,classStr,N=1,K=31):\n",
    "        if classStr == 'regressor':\n",
    "            self.__model = self.__neuralNetworkRegressor(N,K)\n",
    "        elif classStr == 'classifier':\n",
    "            self.__model = self.__neuralNetworkClassifier(N,K)\n",
    "        else:\n",
    "            print('\\nError: model %s not found'%(classStr))\n",
    "        self.__K = K\n",
    "        self.__N = N\n",
    "        self.__xdata = X\n",
    "        self.__ydata = Y\n",
    "        self.__class = classStr\n",
    "    def __neuralNetworkRegressor(self,N,K):\n",
    "        model = Sequential(\n",
    "            [\n",
    "                Dense(\n",
    "                    31*N,\n",
    "                    input_dim=31*N,\n",
    "                    activation='sigmoid', #next layer is relu, so it needs normalization\n",
    "                    kernel_initializer=initializers.GlorotNormal(seed=None), #glorot works good with sigmoid\n",
    "                    bias_initializer='zeros',\n",
    "                ),\n",
    "                Dense(\n",
    "                    K,\n",
    "                    activation='relu', #relu, for better regression\n",
    "                    kernel_initializer=initializers.HeNormal(seed=None), #He Normal goes good with relu\n",
    "                    bias_initializer='zeros',\n",
    "                ),\n",
    "                Dense(\n",
    "                    1,\n",
    "                    kernel_initializer='normal',\n",
    "                    bias_initializer='zeros',\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "        model.compile(loss='mean_squared_error',optimizer='adam',metrics=['accuracy','mse'])\n",
    "        return model\n",
    "    \n",
    "    def __neuralNetworkClassifier(self,N,K):\n",
    "        \n",
    "        model = Sequential(\n",
    "            [\n",
    "                Dense(\n",
    "                    31*N,\n",
    "                    input_dim=31*N,\n",
    "                    activation='relu',\n",
    "                    kernel_initializer=initializers.HeNormal(seed=None), #He Normal goes good with relu\n",
    "                    bias_initializer='zeros',\n",
    "                ),\n",
    "                Dense(\n",
    "                    K,\n",
    "                    activation='relu', \n",
    "                    kernel_initializer=initializers.HeNormal(seed=None), #He Normal goes good with relu\n",
    "                    bias_initializer='zeros',\n",
    "                ),\n",
    "                Dense(\n",
    "                    1,\n",
    "                    activation='sigmoid',\n",
    "                    kernel_initializer='normal',\n",
    "                    bias_initializer='zeros',\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "        model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy','mse'])\n",
    "        return model\n",
    "    \n",
    "    def trainNetwork(self):\n",
    "        xtrain, xtest, ytrain, ytest = train_test_split(self.__xdata,self.__ydata,test_size=0.2)#splitting test-train\n",
    "        print(\"Initiating Training Sequence\\n\")\n",
    "        history = self.__model.fit(\n",
    "            xtrain,\n",
    "            ytrain,\n",
    "            epochs = 10,\n",
    "            batch_size = 5,\n",
    "        )\n",
    "        print(\"\\n\\nInitiating Testing Sequence\\n\")\n",
    "        metrics = self.__model.evaluate(\n",
    "            xtest,\n",
    "            ytest,\n",
    "            batch_size = 5,\n",
    "        )\n",
    "    def evaluateNetwork(self):\n",
    "        '''\n",
    "        This Function isn't really working now,\n",
    "        Will come back later\n",
    "        '''\n",
    "        print(\"\\nInitiating Evaluation Sequence\\n\")\n",
    "        evaluators=[\n",
    "            ('standardize',StandardScaler()),\n",
    "            ('mlp',KerasRegressor(\n",
    "                build_fn =  self.__neuralNetwork(self.__N,self.__K),\n",
    "                epochs = 10,\n",
    "                batch_size = 5,\n",
    "                verbose = 0,\n",
    "            )),\n",
    "        ]\n",
    "        pipeline = Pipeline(evaluators)\n",
    "        results = cross_val_score(\n",
    "            pipeline,\n",
    "            self.__xdata,\n",
    "            self.__ydata,\n",
    "            cv = KFold(n_splits=10)\n",
    "        )\n",
    "        print(\"Standardized: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "romantic-twist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating Training Sequence\n",
      "\n",
      "Epoch 1/10\n",
      "1753/1753 [==============================] - 2s 1ms/step - loss: 61.8509 - accuracy: 0.1655 - mse: 61.8509\n",
      "Epoch 2/10\n",
      "1753/1753 [==============================] - 2s 1ms/step - loss: 53.8696 - accuracy: 0.3865 - mse: 53.8696\n",
      "Epoch 3/10\n",
      "1753/1753 [==============================] - 2s 1ms/step - loss: 52.8578 - accuracy: 0.4070 - mse: 52.8578\n",
      "Epoch 4/10\n",
      "1753/1753 [==============================] - 2s 1ms/step - loss: 52.3592 - accuracy: 0.3919 - mse: 52.3592\n",
      "Epoch 5/10\n",
      "1753/1753 [==============================] - 2s 1ms/step - loss: 52.3757 - accuracy: 0.3768 - mse: 52.3757\n",
      "Epoch 6/10\n",
      "1753/1753 [==============================] - 2s 1ms/step - loss: 51.8695 - accuracy: 0.4177 - mse: 51.8695\n",
      "Epoch 7/10\n",
      "1753/1753 [==============================] - 2s 1ms/step - loss: 51.7442 - accuracy: 0.3780 - mse: 51.7442\n",
      "Epoch 8/10\n",
      "1753/1753 [==============================] - 2s 1ms/step - loss: 51.3598 - accuracy: 0.4115 - mse: 51.3598\n",
      "Epoch 9/10\n",
      "1753/1753 [==============================] - 2s 1ms/step - loss: 51.6027 - accuracy: 0.3895 - mse: 51.6027\n",
      "Epoch 10/10\n",
      "1753/1753 [==============================] - 2s 1ms/step - loss: 51.0899 - accuracy: 0.3870 - mse: 51.0899\n",
      "\n",
      "\n",
      "Initiating Testing Sequence\n",
      "\n",
      "439/439 [==============================] - 0s 1ms/step - loss: 64.5875 - accuracy: 0.3974 - mse: 64.5875\n"
     ]
    }
   ],
   "source": [
    "ydat = rain1\n",
    "xdat = df.values.tolist()\n",
    "rainFallPredictor = predictionModel(xdat,ydat,'regressor',1,10)\n",
    "rainFallPredictor.trainNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "widespread-prague",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating Training Sequence\n",
      "\n",
      "Epoch 1/10\n",
      "1753/1753 [==============================] - 3s 1ms/step - loss: 0.9147 - accuracy: 0.7836 - mse: 0.1758\n",
      "Epoch 2/10\n",
      "1753/1753 [==============================] - 2s 1ms/step - loss: 0.5657 - accuracy: 0.8111 - mse: 0.1448\n",
      "Epoch 3/10\n",
      "1753/1753 [==============================] - 3s 1ms/step - loss: 0.4707 - accuracy: 0.8218 - mse: 0.1332\n",
      "Epoch 4/10\n",
      "1753/1753 [==============================] - 3s 2ms/step - loss: 0.4120 - accuracy: 0.8356 - mse: 0.1227\n",
      "Epoch 5/10\n",
      "1753/1753 [==============================] - 3s 1ms/step - loss: 0.3870 - accuracy: 0.8444 - mse: 0.1161\n",
      "Epoch 6/10\n",
      "1753/1753 [==============================] - 3s 2ms/step - loss: 0.3682 - accuracy: 0.8475 - mse: 0.1126\n",
      "Epoch 7/10\n",
      "1753/1753 [==============================] - 3s 2ms/step - loss: 0.3629 - accuracy: 0.8510 - mse: 0.1112\n",
      "Epoch 8/10\n",
      "1753/1753 [==============================] - 3s 1ms/step - loss: 0.3558 - accuracy: 0.8518 - mse: 0.1102\n",
      "Epoch 9/10\n",
      "1753/1753 [==============================] - 3s 2ms/step - loss: 0.3453 - accuracy: 0.8552 - mse: 0.1070\n",
      "Epoch 10/10\n",
      "1753/1753 [==============================] - 3s 1ms/step - loss: 0.3415 - accuracy: 0.8560 - mse: 0.1055\n",
      "\n",
      "\n",
      "Initiating Testing Sequence\n",
      "\n",
      "439/439 [==============================] - 1s 1ms/step - loss: 0.3330 - accuracy: 0.8586 - mse: 0.1034\n"
     ]
    }
   ],
   "source": [
    "ydata1 = rain1\n",
    "for i in range(len(ydata1)):\n",
    "    if ydata1[i] > 0:\n",
    "        ydata1[i] = 1;\n",
    "xdata1 = df.values.tolist()\n",
    "rainFallPredictor1 = predictionModel(xdata1,ydata1,'classifier',1,200)\n",
    "rainFallPredictor1.trainNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addressed-death",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rain'] = rain1\n",
    "df.drop(df[df['rain'] == 0].index, inplace = True)\n",
    "ydata2 = df['rain'].values.tolist()\n",
    "df = df.drop(['rain'],axis=1)\n",
    "xdata2=df.values.tolist()\n",
    "rainFallPredictor2 = predictionModel(xdata2,ydata2,'regressor',1,400)\n",
    "rainFallPredictor2.trainNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-tiger",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
