{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "amazing-madison",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import initializers\n",
    "import matplotlib.pyplot as mpl\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "missing-dress",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kayde\\OneDrive\\Desktop\\mannada\\RainfallData\n"
     ]
    }
   ],
   "source": [
    "#Get the current working directory\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sapphire-billy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the variables as recorded by the station\n",
    "variables = [\n",
    "        'dswr',\n",
    "        'lftx',\n",
    "        'mslp',\n",
    "        'p__f',\n",
    "        'p__u',\n",
    "        'p__v',\n",
    "        'p__z',\n",
    "        'p_th',\n",
    "        'p_zh',\n",
    "        'p5_f',\n",
    "        'p5_u',\n",
    "        'p5_v',\n",
    "        'p5_z',\n",
    "        'p5th',\n",
    "        'p5zh',\n",
    "        'p8_f',\n",
    "        'p8_u',\n",
    "        'p8_v',\n",
    "        'p8_z',\n",
    "        'p8th',\n",
    "        'p8zh',\n",
    "        'p500',\n",
    "        'p850',\n",
    "        'pottmp',\n",
    "        'pr_wtr',\n",
    "        'prec',\n",
    "        'r500',\n",
    "        'r850',\n",
    "        'rhum',\n",
    "        'shum',\n",
    "        'temp',\n",
    "]\n",
    "\n",
    "#The three regions\n",
    "regions = [\n",
    "        '82.5', #A\n",
    "        '85.0', #B\n",
    "        '87.5', #C\n",
    "]\n",
    "\n",
    "'''\n",
    "TAKING IN ALL THE X VARIABLES\n",
    "'''\n",
    "\n",
    "#define an empty dictionary\n",
    "boxes = {}\n",
    "\n",
    "#iterating over regions\n",
    "for region in regions:\n",
    "    \n",
    "    df_li = pd.DataFrame() # empty dataframe\n",
    "    \n",
    "    #iterating over variables\n",
    "    for var in variables:\n",
    "        \n",
    "        path = os.path.join(cwd,\"DATA\\\\BOX_20N_%sE\\\\ncep_%s.dat\"%(region,var)) # Cleverly curated path for automation\n",
    "        \n",
    "        with open(path) as file: #open the respected variable file for the region\n",
    "            \n",
    "            temp = file.read().splitlines()\n",
    "            temp = [float(i) for i in temp]\n",
    "            \n",
    "        df_li[region + '_' + var] = temp #and for every variable, store that data under header: <coordinate_variable>\n",
    "        \n",
    "    boxes[region]=df_li #and assign that dataframe for every region\n",
    "    \n",
    "'''\n",
    "TAKING IN ALL THE Y VALUES\n",
    "'''\n",
    "\n",
    "rain = []\n",
    "\n",
    "for i in range(5): # iterate from 0 to 4 i.e. 5 times\n",
    "    \n",
    "    path = os.path.join(cwd,\"DATA\\\\rain%d.dat\"%(i+1)) # join cwd to path of rain data\n",
    "    \n",
    "    with open(path) as file:\n",
    "        \n",
    "        lines = file.read().splitlines()\n",
    "        lines = [float(i) for i in lines]\n",
    "        rain.append( lines )  #store in rain list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "searching-producer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#time for some data refining and model training\n",
    "\n",
    "#Trimming BOXES, this is to match with the rain data, day-by-day\n",
    "for region in regions:\n",
    "    boxes[region] = boxes[region].iloc[4749:,] # removing 4749 rows from front\n",
    "    boxes[region] = boxes[region].iloc[:10957,] # keeping only 10957 of the rest\n",
    "\n",
    "#sample take BOX A and PLACE 1\n",
    "df = boxes['82.5']\n",
    "rain1 = rain[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "indoor-quarterly",
   "metadata": {},
   "outputs": [],
   "source": [
    "class predictionModel:\n",
    "    '''\n",
    "    This is a class defining the Prediction Neural Network, Its input filtering,\n",
    "    '''\n",
    "    def __init__(self,X,Y,N=1,K=31):\n",
    "        self.__model = self.__neuralNetwork(N,K)\n",
    "        self.__K = K\n",
    "        self.__N = N\n",
    "        self.__xdata = X\n",
    "        self.__ydata = Y\n",
    "    def __neuralNetwork(self,N,K):\n",
    "        model = Sequential(\n",
    "            [\n",
    "                Dense(\n",
    "                    31*N,\n",
    "                    input_dim=31*N,\n",
    "                    activation='sigmoid', #next layer is relu, so it needs normalization\n",
    "                    kernel_initializer=initializers.GlorotNormal(seed=None), #glorot works good with sigmoid\n",
    "                    bias_initializer='zeros',\n",
    "                ),\n",
    "                Dense(\n",
    "                    K,\n",
    "                    activation='relu', #relu, for better regression\n",
    "                    kernel_initializer=initializers.HeNormal(seed=None), #He Normal goes good with relu\n",
    "                    bias_initializer='zeros',\n",
    "                ),\n",
    "                Dense(\n",
    "                    1,\n",
    "                    kernel_initializer='normal',\n",
    "                    bias_initializer='zeros',\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "        model.compile(loss='mean_squared_error',optimizer='adam',metrics=['accuracy','mse'])\n",
    "        return model\n",
    "    def trainNetwork(self):\n",
    "        xtrain, xtest, ytrain, ytest = train_test_split(self.__xdata,self.__ydata,test_size=0.2)#splitting test-train\n",
    "        print(\"Initiating Training Sequence\")\n",
    "        history = self.__model.fit(\n",
    "            xtrain,\n",
    "            ytrain,\n",
    "            epochs = 20,\n",
    "            batch_size = 5,\n",
    "        )\n",
    "        print(\"\\n\\nInitiating Testing Sequence\")\n",
    "        metrics = self.__model.evaluate(\n",
    "            xtest,\n",
    "            ytest,\n",
    "            batch_size = 5,\n",
    "        )\n",
    "    def evaluateNetwork(self):\n",
    "        evaluators=[\n",
    "            ('standardize',StandardScaler()),\n",
    "            ('mlp',KerasRegressor(\n",
    "                build_fn =  __neuralNetwork(__N,__K),\n",
    "                epochs = 10,\n",
    "                batch_size = 5,\n",
    "                verbose = 0,\n",
    "            )),\n",
    "        ]\n",
    "        pipeline = Pipeline(evaluators)\n",
    "        results = cross_val_score(\n",
    "            pipeline,\n",
    "            xdata,\n",
    "            ydata,\n",
    "            cv = KFold(n_splits)\n",
    "        )\n",
    "        print(\"Standardized: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "romantic-twist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating Training Sequence\n",
      "Epoch 1/20\n",
      "1753/1753 [==============================] - 2s 1ms/step - loss: 62.9487 - accuracy: 0.2153 - mse: 62.9487\n",
      "Epoch 2/20\n",
      "1753/1753 [==============================] - 2s 1ms/step - loss: 57.6805 - accuracy: 0.3603 - mse: 57.6805\n",
      "Epoch 3/20\n",
      "1753/1753 [==============================] - 2s 1ms/step - loss: 56.8043 - accuracy: 0.3804 - mse: 56.8043\n",
      "Epoch 4/20\n",
      "1753/1753 [==============================] - 2s 1ms/step - loss: 56.3170 - accuracy: 0.3442 - mse: 56.3170\n",
      "Epoch 5/20\n",
      "1753/1753 [==============================] - 2s 1ms/step - loss: 55.8627 - accuracy: 0.3851 - mse: 55.8627\n",
      "Epoch 6/20\n",
      "1753/1753 [==============================] - 2s 1ms/step - loss: 55.3490 - accuracy: 0.3836 - mse: 55.3490\n",
      "Epoch 7/20\n",
      "1753/1753 [==============================] - 2s 1ms/step - loss: 55.2675 - accuracy: 0.3927 - mse: 55.2675\n",
      "Epoch 8/20\n",
      "1753/1753 [==============================] - 2s 1ms/step - loss: 55.2751 - accuracy: 0.4042 - mse: 55.2751\n",
      "Epoch 9/20\n",
      "1753/1753 [==============================] - 2s 1ms/step - loss: 55.5136 - accuracy: 0.3967 - mse: 55.5136\n",
      "Epoch 10/20\n",
      "1753/1753 [==============================] - 2s 1ms/step - loss: 55.3543 - accuracy: 0.3594 - mse: 55.3543\n",
      "Epoch 11/20\n",
      "1753/1753 [==============================] - 2s 1ms/step - loss: 55.5018 - accuracy: 0.3705 - mse: 55.5018\n",
      "Epoch 12/20\n",
      "1753/1753 [==============================] - 3s 1ms/step - loss: 54.9736 - accuracy: 0.4118 - mse: 54.9736: 0s - loss: 55.\n",
      "Epoch 13/20\n",
      "1753/1753 [==============================] - 3s 2ms/step - loss: 55.0341 - accuracy: 0.3971 - mse: 55.0341\n",
      "Epoch 14/20\n",
      "1753/1753 [==============================] - 2s 1ms/step - loss: 55.0151 - accuracy: 0.3813 - mse: 55.0151\n",
      "Epoch 15/20\n",
      "1753/1753 [==============================] - 3s 2ms/step - loss: 55.2814 - accuracy: 0.3739 - mse: 55.2814\n",
      "Epoch 16/20\n",
      "1753/1753 [==============================] - 2s 1ms/step - loss: 54.9370 - accuracy: 0.3997 - mse: 54.9370\n",
      "Epoch 17/20\n",
      "1753/1753 [==============================] - 2s 1ms/step - loss: 55.3588 - accuracy: 0.3394 - mse: 55.3588\n",
      "Epoch 18/20\n",
      "1753/1753 [==============================] - 2s 1ms/step - loss: 55.5420 - accuracy: 0.3945 - mse: 55.5420\n",
      "Epoch 19/20\n",
      "1753/1753 [==============================] - 2s 1ms/step - loss: 55.3916 - accuracy: 0.3630 - mse: 55.3916\n",
      "Epoch 20/20\n",
      "1753/1753 [==============================] - 2s 1ms/step - loss: 55.4962 - accuracy: 0.3791 - mse: 55.4962\n",
      "\n",
      "\n",
      "Initiating Testing Sequence\n",
      "439/439 [==============================] - 0s 1ms/step - loss: 46.3211 - accuracy: 0.5420 - mse: 46.3211\n"
     ]
    }
   ],
   "source": [
    "ydat = rain1\n",
    "xdat = df.values.tolist()\n",
    "rainFallPredictor = predictionModel(xdat,ydat,1,31)\n",
    "rainFallPredictor.trainNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-jason",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
